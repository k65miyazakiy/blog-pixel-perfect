---
title: "Cloud BuildのパイプラインのみでE2Eテストを実現する"
createdAt: "2025-04-26"
tags:
  - tech
  - cicd
  - cloudbuilc
  - e2e
  - playwright
type: "techtips"
---

CICDでE2Eテストを実行する際、CICDサービス以外の環境にアプリをデプロイしてその後E2Eテストを実行する、などの手順に煩雑さを感じることはないでしょうか。
特別な目的があるのであればそのような構成を採用すればよいと思います。
しかし、**構成要素どうしが正しく連携できるか、APIは定義側呼び出し側で相違ないか、などを確認するベター結合試験的な目的であればCICD環境内で完結できるとシンプルで嬉しい**と思います。

本稿では、Google Cloud Buildを用いてそのような複数のサービス間が協調して動作するサービス環境を立ち上げ、実際にE2E的な疎通を確認する方法を紹介します。

## 何が問題なのか？

CICDはビルドタスクは順々に実行されるので、前述の概念を実現させるのは簡単そうに思えます。
つまり、ステップごとに

1. アプリをビルドする
2. 初期データの登録など、アプリの実行環境を整える
3. アプリを実行する
4. 任意のテストィングソフトでアプリに対してアクセスする

などとしてやればよさそうです。

しかし、実際にパイプライン定義を書き始めてみると意外と障壁が多くあります。具体的には

1. あるステップで生成したファイルを後続ファイルはどのように利用すればよいか
2. アプリケーションをステップを跨いで永続化するには
3. 起動したアプリケーションに対してどのようにアクセスできるのか

などです。

本稿では、上述の事象に対してCloud Buildの仕様を確認しながら解決のポイントを説明していきます。

<Caution message="アプリに関しては実装によって千差万別なので、ここではインフラ面を重点的に説明します。
アプリ面で言うと外部システムのモッキングや認証の迂回方法が課題になってくると思います。" />

はじめにざっくりいうと、**定義したパイプラインおよびステップはどのような環境で実行されるのか、というCloud Buildの基礎的な知識が重要**になってきます。
なので、最初にCloud Buildの基盤仕様をざっくり確認しておきましょう。

## Cloud Buildの基盤仕様

まず重要な点ですが、**Cloud Buildではビルドの各ステップはDockerコンテナとして実行**されます[*](https://cloud.google.com/build/docs/overview?hl=ja#docker)。
この点の理解を深めるため、各ステップが具体的にどのようなコマンドとして翻訳されるのか（大雑把に）見ていきましょう。

Cloud Buildでのビルド定義はjsonやyamlで記述されます。
例えば[公式ドキュメントから拾ってきた次のyaml](https://cloud.google.com/build/docs/build-config-file-schema?hl=ja)を考えます。

<CB
  lang="yaml"
  fileName="cloudbuild_sample1.yaml"
  content={`
steps:
- name: 'gcr.io/cloud-builders/mvn'
  args: ['install']
- name: 'gcr.io/cloud-builders/docker'
  args: ['build', '-t', 'gcr.io/my-project-id/myimage', '.']
`} />

このスニペットは2つのステップから構成されていて、何をやっているかはなんとなくわかると思います。
最初のステップでは`mvn install`でJavaアプリケーションのビルドに必要な依存をDLし、次のステップでdockerイメージとしてビルドを行っています。

<Info message="ちょっと誤解しやすいところですが、stepsのnameプロパティ使用するコンテナのIDを指定します。任意の論理名ではないです" />

上記のステップをより具体的なコマンドに翻訳すると、

1. `docker run gcr.io/cloud-builders/mvn mvn install`
2. `docker run gcr.io/cloud-builders/docker docker build -t gcr.io/my-project-id/myimage .`

といった具合になります。

当然、**ビルドごとに別のコンテナが起動されるので、コンテナ内のファイルは基本的に次のステップに持ち越すことはできません**。
また、**ステップの成功/失敗判定はコンテナの終了ステータスをもとにするので、あるステップでアプリを立ち上げて後続のステップでアクセスする、ということも基本出来ません**。
（前のステップが終了しないとそもそも次に進まないので）

なので、**前述の課題はもう少し具体的な表現に落とすとCloud Buildがこのようなアーキテクチャである前提で、どのような技術的方法でこの制約を迂回できるかを探すこと**になります。
以降、具体的な方法を見ていきます。

## パワー案：1つのステップで全てを行う

最初に**パワー系の別解を紹介しますが、そもそも1つのコンテナで全部やればよいという発想**もあります。

具体的には`bash -c`コマンドを利用します。これは引数で受け取った任意のBashシェルコマンドを実行できるうえに、なんなら複数行のコマンドを受け付けます。

<CB  lang="text"
  fileName="bash-c"
  content={`// bashコマンドライン命令
>> /bin/bash -c 'echo "Command 1"                                                                                                                                                                    127 ↵ kussaka@kussatu-win11
echo "Command 2"'

// 実行結果
Command 1
Command 2`} />

なので、これを利用して「依存の取得」、「ビルド」、「アプリの起動」、「テスト」を全てスクリプト形式で1ステップ中に書けばよいです。最初に挙げた課題は全部解決します。
仕組み上複数のプロセスを動作させることになるので、適宜後続の処理でアクセスが必要なサービスはバックグラウンドとして起動することになります。

<Caution message="バックグラウンドで起動させてーの流れまでは実際に検証できておらず、机上レベルな部分です" />

「アプリの起動」や「テスト」までの必要な処理量が少ない場合などはこれで十分なことも多いでしょう。

ただしこの方法は、**複数のサービスが協働したりその動作環境が異なったりする場合を考えると逆に面倒になることも多い**です。
アプリの起動やビルドのためにGoを入れてPythonを入れてNodeも入れて、さらにPlaywrightを入れてーなどなると流石に既存のコンテナイメージを活かした方が楽になるでしょう。
また、そもそも**アプリイメージがレジストリにデプロイされているなら、そのイメージを活用して面倒なビルドプロセスを丸ごと省くことも可能**になります。

以降は、Cloud Buildの仕様をより深掘りして、より複雑な状況においても前述の課題に対応できるような方法を説明していきます。

## 課題１：後続ステップへのデータ・ファイルの受け渡し

まずはステップ中でのデータの永続化方法です。

Cloud BuildのステップはDockerコンテナなら、**コンテナ終了後のデータの永続化にはテンプレがあります。つまり、ボリューム（やマウント）を使えばよい**のでは？ということです。
実際その通りで、**[Cloud Buildでは暗黙的に`workspace`というボリュームを用意しており、コンテナのパス`/workspace`にマウント](https://cloud.google.com/build/docs/build-config-file-schema?hl=ja#yaml_28)します**（同名なのでちょっとややこしいですね）。
なので、**コンテナ上で`/workspace`フォルダで生成、変更したファイルはそのまま以降のステップで利用可能**になります。

また、実はそもそも**Cloud Buildでは、コンテナ上の`/workspace`というフォルダはデフォルトの作業ディレクトリCWD**です。

さらに、[レポジトリ連携をする場合（ほぼすると思います）は、レポジトリのシャローコピーが`/workspace`にコピー](https://cloud.google.com/build/docs/automating-builds/github/connect-repo-github?hl=ja)されます。

<BQ> ビルドを実行すると、Cloud Build は、リポジトリの内容を Cloud Build のデフォルトの作業ディレクトリ（/workspace）にコピーします。 </BQ>

上記の話をまとめると、**コンテナのデフォルトの作業ディレクトリはレポジトリのルートディレクトリとなり、かつデータはパイプライン全体で共有される**となります。
つまり、ここまでいろいろ書いてきたものの、そもそも気にしなくてもデータの共有は可能な場面が多いです。

ただし、作業ディレクトリを変更したり、あるいは依存のインストールが作業ディレクトリ外で行われるような場合は前述の通りデータが共有されないので、このような時には本項の説明がヒントになると思います。

## 課題２：プロセスの永続化

次はプロセスの永続化です。言い換えれば、あるステップでアプリケーションを起動した状態で次のステップに進むにはどうしたらいいか、ということです。

先述の通り、Cloud Buildのステップの進行判定は現在進行中のステップの終了ステータスをもとにします。
そのため、あるステップでアプリケーションを起動したまま次のステップに進むことはできません。

この問題に対応するため、ここで紹介するのは**Cloud Buildのステップ中でDockerの起動コマンドを実行し、ステップコンテナとは別のコンテナを立ち上げる**という方法です。
Dockerコマンドを実行したコンテナ（ビルドコンテナ）はコマンド実行後終了するのでパイプラインは進みます。
かつその立ち上げられたコンテナはパイプラインが直接管理するコンテナでなく、自動的に終了もさせられないので後続のステップからアクセス可能になります。

具体的なパイプライン定義のyamlを見てみましょう。